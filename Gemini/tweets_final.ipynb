{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "import json\n",
        "import glob\n",
        "\n",
        "# Set up the Gemini API client\n",
        "api_key = \"AIzaSyAMVWspHCAo4P8Tld7dYF24jRUDbYILa6s\"  # Replace with your actual API key\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# Define directories\n",
        "storage_dir = \"Storage\"\n",
        "temp_texts_dir = os.path.join(storage_dir, \"temp_texts\")\n",
        "temp_tweets_dir = os.path.join(storage_dir, \"temp_tweets\")\n",
        "\n",
        "# Create the tweet storage directory if it doesn't exist\n",
        "os.makedirs(temp_tweets_dir, exist_ok=True)\n",
        "\n",
        "# Initialize the model\n",
        "model = genai.GenerativeModel('gemini-2.0-flash-thinking-exp')\n",
        "\n",
        "def generate_tweet(book_data):\n",
        "    \"\"\"Generate an engaging tweet for a book using Gemini AI\"\"\"\n",
        "\n",
        "    # Extract book information\n",
        "    title = book_data[\"title\"]\n",
        "    author = book_data[\"author\"]\n",
        "    synopsis = book_data[\"synopsis\"]\n",
        "\n",
        "    # Create the prompt for generating a tweet\n",
        "    prompt = f\"\"\"Create an engaging, attention-grabbing tweet to promote this book:\n",
        "\n",
        "    Title: {title}\n",
        "    Author: {author}\n",
        "    Synopsis: {synopsis}\n",
        "\n",
        "    The tweet should:\n",
        "    1. Be between 200-240 characters (to leave room for hashtags and links)\n",
        "    2. Include an emoji or two naturally integrated in the text for visual appeal\n",
        "    3. Have a compelling hook that makes readers want to learn more\n",
        "    4. Capture the essence and emotion of the book\n",
        "    5. End with 2-3 relevant hashtags\n",
        "\n",
        "    Return ONLY the complete tweet text, with emojis naturally integrated and hashtags at the end.\n",
        "    Do not include any JSON formatting or explanations.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Generate content\n",
        "        response = model.generate_content(prompt)\n",
        "        tweet_text = response.text.strip()\n",
        "\n",
        "        # Clean up any potential markdown or formatting\n",
        "        if tweet_text.startswith('```') and tweet_text.endswith('```'):\n",
        "            tweet_text = tweet_text[3:-3].strip()\n",
        "\n",
        "        # Calculate character count\n",
        "        char_count = len(tweet_text)\n",
        "\n",
        "        return {\n",
        "            \"tweet_text\": tweet_text,\n",
        "            \"character_count\": char_count\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating tweet: {e}\")\n",
        "        fallback_tweet = f\"Discover '{title}' by {author} - an exciting new release that will captivate your imagination! ðŸ“šâœ¨ #NewBook #MustRead\"\n",
        "        return {\n",
        "            \"tweet_text\": fallback_tweet,\n",
        "            \"character_count\": len(fallback_tweet)\n",
        "        }\n",
        "\n",
        "# Get all book JSON files\n",
        "book_files = glob.glob(os.path.join(temp_texts_dir, \"book_*.json\"))\n",
        "\n",
        "# Process each book file\n",
        "for book_file in book_files:\n",
        "    # Extract the book number from the filename\n",
        "    book_num = book_file.split(\"book_\")[1].split(\".json\")[0]\n",
        "\n",
        "    # Read the book data\n",
        "    try:\n",
        "        with open(book_file, 'r', encoding='utf-8') as f:\n",
        "            book_data = json.load(f)\n",
        "\n",
        "        print(f\"Generating tweet for book {book_num}: {book_data['title']}...\")\n",
        "\n",
        "        # Generate a tweet for the book\n",
        "        tweet_data = generate_tweet(book_data)\n",
        "\n",
        "        # Save just the tweet text to a .txt file\n",
        "        txt_output_file = os.path.join(temp_tweets_dir, f\"tweet_{book_num}.txt\")\n",
        "        with open(txt_output_file, 'w', encoding='utf-8') as f:\n",
        "            f.write(tweet_data[\"tweet_text\"])\n",
        "\n",
        "        print(f\"Saved tweet to {txt_output_file}\")\n",
        "        print(f\"Tweet: {tweet_data['tweet_text']}\")\n",
        "        print(f\"Character count: {tweet_data['character_count']}\")\n",
        "        print(\"------------------------------------\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing book {book_num}: {e}\")\n",
        "\n",
        "print(\"All tweets have been generated and saved as text files!\")"
      ],
      "metadata": {
        "id": "gSj6fvmV63bt"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}